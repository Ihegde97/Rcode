% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={HA8},
  pdfauthor={Ishwara Hegde, Jonathan Nieman, Aleksei Samkov},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\title{HA8}
\author{Ishwara Hegde, Jonathan Nieman, Aleksei Samkov}
\date{30/11/2020}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

The purpose of this introduction is to give a brief recap of the methods
that we will see in the empirical exercise below. Most of the material
here is taken from Dmitry's new paper,``Synthetic Difference in
Differences''. You can check it out (highly recommended)
\href{https://arxiv.org/pdf/1812.09970.pdf}{here}.

\hypertarget{setup}{%
\subsubsection{Setup}\label{setup}}

\begin{itemize}
\tightlist
\item
  We want to estimate the impact of some policy using panel data.
\item
  Policy changes not random -- neither across units or time.
\item
  We want to connect connect observed data to unobserved
  counterfactuals.
\end{itemize}

\hypertarget{solutions}{%
\subsubsection{Solutions}\label{solutions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DiD : requires parallel trends and large number of units exposed
\item
  Synthetic control (SC): small no. of units and no parallel trends.
\end{enumerate}

In the paper linked above, Dmitry et. al combine these two methods and
call it Synthetic Difference-in-Differences:

\begin{itemize}
\item
  Like SC, the method re-weights and matches pre-exposure trends to
  weaken the reliance on parallel trend type assumptions.
\item
  Like DID, it is invariant to additive unit-level shifts.
\end{itemize}

\hypertarget{mathematical-details}{%
\subsubsection{Mathematical Details}\label{mathematical-details}}

Recall in DiD we obtain the estimates by solving the following TWFE
model:

\(\tau ^{did},\hat{\mu}, \hat{\alpha},\hat{\beta }=\) arg min
\$\sum\_i\^{}N \sum\emph{t\^{}T (Y}\{it\}- \mu -\alpha\_i-\beta\emph{t
-W}\{it\}\tau)\^{}2 \$

In SC we solve the following problem:

\$\tau \^{}\{SC\},\hat{\mu}, \hat{\alpha},\hat{\beta }= \$ arg min \$
\{\sum\_i\^{}N \sum\emph{t\^{}T (Y}\{it\}- \mu -\beta\emph{t
-W}\{it\}\tau)\^{}2 \omega\_i \^{}\{SC\}\}\$

Where weights \$\omega \^{}\{SC\} \$ align pre-exposure trends in the
outcome of unexposed units with those for the exposed units.

Now SDID solves the following:

\$\tau \^{}\{SC\},\hat{\mu}, \hat{\alpha},\hat{\beta }= \$ arg min \$
\{\sum\_i\^{}N \sum\emph{t\^{}T (Y}\{it\}- \mu -\alpha\_i-\beta\emph{t
-W}\{it\}\tau)\^{}2 \omega\_i \^{}\{SC\} \lambda\_t \^{}\{SDID\}\}\$

Notice it introduces two new things:

\begin{itemize}
\tightlist
\item
  With respect to DID, SDID adds the unit and time weights.
\item
  With respect to SC, SDID adds the unit level fixed effects.
\end{itemize}

\begin{quote}
Unit weights are designed so that the average outcome for the treated
units are approximately parallel to the averages for control units. Time
weights are designed so that, acknowledging that the difference between
treated and control averages varies over the pre-treatment period, we
adjust for the right pre-treatment difference: the difference during
periods that are predictive of what happens after treatment.
\end{quote}

Unit fixed effects in applications is found to explain much of the
variation therefore its inclusion reduces bias with respect to standard
SC.

\hypertarget{load-and-normalize-data}{%
\subsubsection{1. Load and normalize
data}\label{load-and-normalize-data}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load data}
\KeywordTok{load}\NormalTok{(}\StringTok{"cps_data.Rdata"}\NormalTok{)}

\CommentTok{# Define initial parameters}
\NormalTok{n <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(Y)[}\DecValTok{1}\NormalTok{]}
\NormalTok{T <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(Y)[}\DecValTok{2}\NormalTok{]}
\NormalTok{T_}\DecValTok{0}\NormalTok{ <-}\StringTok{ }\DecValTok{30}

\CommentTok{# Normalize Y}
\NormalTok{Y_norm <-}\StringTok{ }\NormalTok{(Y}\OperatorTok{-}\KeywordTok{mean}\NormalTok{(Y))}\OperatorTok{/}\KeywordTok{sd}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

\hypertarget{construct-svd}{%
\subsubsection{2. Construct SVD}\label{construct-svd}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y_svd <-}\StringTok{ }\KeywordTok{svd}\NormalTok{(Y_norm)}

\NormalTok{M <-}\StringTok{ }\NormalTok{Y_svd}\OperatorTok{$}\NormalTok{u[,}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{] }\OperatorTok{%*%}\StringTok{ }\KeywordTok{diag}\NormalTok{(Y_svd}\OperatorTok{$}\NormalTok{d[}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{]) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(Y_svd}\OperatorTok{$}\NormalTok{v[,}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{])}
\NormalTok{E <-}\StringTok{ }\NormalTok{Y_svd}\OperatorTok{$}\NormalTok{u[,}\DecValTok{5}\OperatorTok{:}\NormalTok{T] }\OperatorTok{%*%}\StringTok{ }\KeywordTok{diag}\NormalTok{(Y_svd}\OperatorTok{$}\NormalTok{d[}\DecValTok{5}\OperatorTok{:}\NormalTok{T]) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(Y_svd}\OperatorTok{$}\NormalTok{v[,}\DecValTok{5}\OperatorTok{:}\NormalTok{T])}

\NormalTok{sig2_e <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(E}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\NormalTok{(n}\OperatorTok{*}\NormalTok{T)}

\CommentTok{# Confirm M+E equals normalized Y}
\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(Y_norm}\OperatorTok{-}\NormalTok{(M}\OperatorTok{+}\NormalTok{E)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.132427e-14
\end{verbatim}

\hypertarget{decompose-m-into-two-components}{%
\subsubsection{3. Decompose M into two
components}\label{decompose-m-into-two-components}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n_ones <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{nrow=}\NormalTok{n, }\DataTypeTok{ncol=}\NormalTok{n)}
\NormalTok{T_ones <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{nrow=}\NormalTok{T, }\DataTypeTok{ncol=}\NormalTok{T)}

\NormalTok{F <-}\StringTok{ }\NormalTok{(n_ones }\OperatorTok{%*%}\StringTok{ }\NormalTok{M}\OperatorTok{/}\NormalTok{n) }\OperatorTok{+}\StringTok{ }\NormalTok{(M }\OperatorTok{%*%}\StringTok{ }\NormalTok{T_ones}\OperatorTok{/}\NormalTok{T)}
\NormalTok{L <-}\StringTok{ }\NormalTok{M}\OperatorTok{-}\NormalTok{F}
\end{Highlighting}
\end{Shaded}

\hypertarget{run-a-logit-of-d_i-on-u_1-u_4-and-extract-predicted-probabilities}{%
\subsubsection{\texorpdfstring{4. Run a logit of \(D_i\) on
\({u_1-u_4}\) and extract predicted
probabilities}{4. Run a logit of D\_i on \{u\_1-u\_4\} and extract predicted probabilities}}\label{run-a-logit-of-d_i-on-u_1-u_4-and-extract-predicted-probabilities}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{u <-}\StringTok{ }\NormalTok{Y_svd}\OperatorTok{$}\NormalTok{u[,}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{]}
\NormalTok{pi <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(D}\OperatorTok{~}\NormalTok{u, }\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{)}\OperatorTok{$}\NormalTok{fitted.values}
\end{Highlighting}
\end{Shaded}

\hypertarget{define-dgp-function}{%
\subsubsection{5. Define DGP function}\label{define-dgp-function}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DGP_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, T, a_}\DecValTok{0}\NormalTok{, a_}\DecValTok{1}\NormalTok{, F, L, sig2_e, pi) \{}
\NormalTok{  A <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DecValTok{1}\NormalTok{, pi)}
\NormalTok{  epsilon <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(T}\OperatorTok{*}\NormalTok{n, }\DataTypeTok{mean=}\DecValTok{0}\NormalTok{, }\DataTypeTok{sd=}\KeywordTok{sqrt}\NormalTok{(sig2_e)), n, T)}

\NormalTok{  Y <-}\StringTok{ }\NormalTok{a_}\DecValTok{0}\OperatorTok{*}\NormalTok{F }\OperatorTok{+}\StringTok{ }\NormalTok{a_}\DecValTok{1}\OperatorTok{*}\NormalTok{L }\OperatorTok{+}\StringTok{ }\NormalTok{epsilon }
\NormalTok{  W <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow=}\NormalTok{n, }\DataTypeTok{ncol=}\NormalTok{T_}\DecValTok{0}\NormalTok{), }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{nrow=}\NormalTok{n, }\DataTypeTok{ncol=}\NormalTok{T}\OperatorTok{-}\NormalTok{T_}\DecValTok{0}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\NormalTok{A}

\NormalTok{  data_returned <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{"Y"}\NormalTok{ =}\StringTok{ }\NormalTok{Y, }\StringTok{"W"}\NormalTok{ =}\StringTok{ }\NormalTok{W)}
  \KeywordTok{return}\NormalTok{(data_returned)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{simulate-data-and-compute-estimators}{%
\subsubsection{6. Simulate data and compute
estimators}\label{simulate-data-and-compute-estimators}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B <-}\StringTok{ }\DecValTok{400}
\NormalTok{tau_hat <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow =}\NormalTok{ B, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(tau_hat) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"tau_DID"}\NormalTok{, }\StringTok{"tau_SC"}\NormalTok{, }\StringTok{"tau_SDID"}\NormalTok{)}

\ControlFlowTok{for}\NormalTok{ (b }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{B)\{}
\NormalTok{  draw <-}\StringTok{ }\KeywordTok{DGP_1}\NormalTok{(n, T, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, F, L, sig2_e, pi)}
\NormalTok{  rowsort <-}\StringTok{ }\KeywordTok{order}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T])}

\NormalTok{  data_Y <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{Y[rowsort,]}
\NormalTok{  data_W <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{W[rowsort,]}
  
\NormalTok{  n_}\DecValTok{0}\NormalTok{ <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T]}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
  
\NormalTok{  tau_hat[b,}\DecValTok{1}\NormalTok{] <-}\StringTok{      }\KeywordTok{did_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat[b,}\DecValTok{2}\NormalTok{] <-}\StringTok{       }\KeywordTok{sc_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat[b,}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\KeywordTok{synthdid_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{plot-the-distribution-of-did-and-sdid-estimators.}{%
\subsubsection{7. Plot the distribution of DID and SDID
estimators.}\label{plot-the-distribution-of-did-and-sdid-estimators.}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Define plotting function}
\NormalTok{plotting_func <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(data, x_string)\{}
\NormalTok{  p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data=}\NormalTok{data, }\DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x_string)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom_density}\NormalTok{(}\DataTypeTok{kernel=}\StringTok{"gaussian"}\NormalTok{, }\DataTypeTok{adjust=}\FloatTok{1.8}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_vline}\NormalTok{(}\DataTypeTok{xintercept=}\DecValTok{0}\NormalTok{, }\DataTypeTok{linetype=}\StringTok{"dotted"}\NormalTok{, }\DataTypeTok{color=}\StringTok{"blue"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme_minimal}\NormalTok{()}
  \KeywordTok{return}\NormalTok{(p)}
\NormalTok{\}}

\CommentTok{# Create the plots for DGP 1 }
\NormalTok{tau_hat <-}\StringTok{ }\KeywordTok{data.table}\NormalTok{(tau_hat)}
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{plotting_func}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tau_hat, }\DataTypeTok{x_string =}\NormalTok{ tau_hat}\OperatorTok{$}\NormalTok{tau_DID) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Diff-in-Diff"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\OperatorTok{-}\NormalTok{.}\DecValTok{15}\NormalTok{,.}\DecValTok{15}\NormalTok{)}
\NormalTok{p2 <-}\StringTok{ }\KeywordTok{plotting_func}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tau_hat, }\DataTypeTok{x_string =}\NormalTok{ tau_hat}\OperatorTok{$}\NormalTok{tau_SC) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Synthetic Controls"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\OperatorTok{-}\NormalTok{.}\DecValTok{15}\NormalTok{,.}\DecValTok{15}\NormalTok{)}
\NormalTok{p3 <-}\StringTok{ }\KeywordTok{plotting_func}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ tau_hat, }\DataTypeTok{x_string =}\NormalTok{ tau_hat}\OperatorTok{$}\NormalTok{tau_SDID) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Synthetic Diff-in-Diff"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\OperatorTok{-}\NormalTok{.}\DecValTok{15}\NormalTok{,.}\DecValTok{15}\NormalTok{)}

\NormalTok{p_dgp1 <-}\StringTok{ }\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2 }\OperatorTok{+}\StringTok{ }\NormalTok{p3 }\OperatorTok{+}\StringTok{ }\KeywordTok{plot_annotation}\NormalTok{(}
  \DataTypeTok{title =} \StringTok{"DGP 1: Distribution of Estimator Bias"}\NormalTok{,}
  \DataTypeTok{subtitle =} \StringTok{"alpha_0 = alpha_1 = 1"}
\NormalTok{)}

\NormalTok{p_dgp1}
\end{Highlighting}
\end{Shaded}

\includegraphics{PS8-Q2.1_files/figure-latex/plots1-1.pdf}

It is clear that the bias of the diff-in-diff estimator is larger both
in terms of its mean and its variance. Allowing the weights assigned to
each data point to vary in both dimensions helps to correct for the fact
that our treated subsample does not follow perfect parallel trends with
the untreated subsample. It also helps to correct for imbalances in the
propensity for treatment across the treated and untreated subsamples.

\hypertarget{repeat-dgp-and-estimation-for-alternative-alpha-parametrizations.}{%
\subsubsection{8. Repeat DGP and estimation for alternative alpha
parametrizations.}\label{repeat-dgp-and-estimation-for-alternative-alpha-parametrizations.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tau_hat2 <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow =}\NormalTok{ B, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{)}
\NormalTok{tau_hat3 <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow =}\NormalTok{ B, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(tau_hat2) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"tau_DID"}\NormalTok{, }\StringTok{"tau_SC"}\NormalTok{, }\StringTok{"tau_SDID"}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(tau_hat3) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"tau_DID"}\NormalTok{, }\StringTok{"tau_SC"}\NormalTok{, }\StringTok{"tau_SDID"}\NormalTok{)}

\ControlFlowTok{for}\NormalTok{ (b }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{B)\{}
  \CommentTok{# Alternative Draw #1 - alpha_0 = 1, alpha_1 = 0}
\NormalTok{  draw <-}\StringTok{ }\KeywordTok{DGP_1}\NormalTok{(n, T, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, F, L, sig2_e, pi)}
  
\NormalTok{  rowsort <-}\StringTok{ }\KeywordTok{order}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T])}
\NormalTok{  data_Y <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{Y[rowsort,]}
\NormalTok{  data_W <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{W[rowsort,]}
  
\NormalTok{  n_}\DecValTok{0}\NormalTok{ <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T]}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
  
\NormalTok{  tau_hat2[b,}\DecValTok{1}\NormalTok{] <-}\StringTok{      }\KeywordTok{did_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat2[b,}\DecValTok{2}\NormalTok{] <-}\StringTok{       }\KeywordTok{sc_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat2[b,}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\KeywordTok{synthdid_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}

  \CommentTok{# Alternative Draw #2 - alpha_0 = 0, alpha_1 = 1}
\NormalTok{  draw <-}\StringTok{ }\KeywordTok{DGP_1}\NormalTok{(n, T, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, F, L, sig2_e, pi)}
  
\NormalTok{  rowsort <-}\StringTok{ }\KeywordTok{order}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T])}
\NormalTok{  data_Y <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{Y[rowsort,]}
\NormalTok{  data_W <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{W[rowsort,]}
  
\NormalTok{  n_}\DecValTok{0}\NormalTok{ <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T]}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
  
\NormalTok{  tau_hat3[b,}\DecValTok{1}\NormalTok{] <-}\StringTok{      }\KeywordTok{did_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat3[b,}\DecValTok{2}\NormalTok{] <-}\StringTok{       }\KeywordTok{sc_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat3[b,}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\KeywordTok{synthdid_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{\}}

\KeywordTok{datasummary_skim}\NormalTok{(tau_hat)}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}[t]{lrrrrrrr>{}r}
\toprule
  & Unique (\#) & Missing (\%) & Mean & SD & Min & Median & Max &   \\
\midrule
tau\_DID & 400 & 0 & 0.0 & 0.0 & -0.1 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956763767.png}\\
tau\_SC & 400 & 0 & 0.0 & 0.0 & -0.1 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956763824.png}\\
tau\_SDID & 400 & 0 & 0.0 & 0.0 & -0.1 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956763858.png}\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{datasummary_skim}\NormalTok{(tau_hat2)}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}[t]{lrrrrrrr>{}r}
\toprule
  & Unique (\#) & Missing (\%) & Mean & SD & Min & Median & Max &   \\
\midrule
tau\_DID & 400 & 0 & 0.0 & 0.0 & -0.0 & -0.0 & 0.0 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956764211.png}\\
tau\_SC & 400 & 0 & 0.0 & 0.0 & -0.0 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956764246.png}\\
tau\_SDID & 400 & 0 & 0.0 & 0.0 & -0.0 & -0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956764274.png}\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{datasummary_skim}\NormalTok{(tau_hat3)}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}[t]{lrrrrrrr>{}r}
\toprule
  & Unique (\#) & Missing (\%) & Mean & SD & Min & Median & Max &   \\
\midrule
tau\_DID & 400 & 0 & 0.0 & 0.0 & -0.1 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956764646.png}\\
tau\_SC & 400 & 0 & 0.0 & 0.0 & -0.1 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956764678.png}\\
tau\_SDID & 400 & 0 & 0.0 & 0.0 & -0.1 & 0.0 & 0.1 & \includegraphics[width=0.67in, height=0.17in]{PS8-Q2.1_files/figure-latex/hist_1606956764722.png}\\
\bottomrule
\end{tabular}
\end{table}

Each parametrization helps to reveal a bit more about the bias issues in
each estimation strategy. First, we should understand the interpretation
of \(\alpha_0\) and \(\alpha_1\). \(\alpha_0\) determines whether or not
the data draws include \(\textbf{F}\), which in our simulated data is
like a two-way fixed effect component (summing the time-mean and
unit-mean of \(\textbf{M}\)). \(\alpha_1\) does the same for
\(\textbf{L}=\textbf{M}-\textbf{F}\), which contains the remaining
unit-time interaction component. Note that \(\textbf{M}\) contains the
four principal components of the SVD of \(\tilde{\textbf{Y}}\), which we
can think of as the systematic component of the data (with
\(\textbf{E}\) being the noise).

When \(\alpha_0=\alpha_1=1\), the synthetic diff-in-diff estimator is
the least biased and most efficient.

When \(\alpha_0=1\) and \(\alpha_1=0\), the regulator diff-in-diff
estimator is the best estimator but is only marginally better than
synthetic diff-in-diff. This is because only the fixed effect component
is included in the data generation, so the parallel trends assumption
holds by construction.

When \(\alpha_0=0\) and \(\alpha_1=1\), the synthetic controls estimator
is the best but again is only marginally better than synthetic
diff-in-diff.

\hypertarget{repeat-parts-5-7-but-with-an-alternative-dgp}{%
\subsubsection{9. Repeat parts 5-7 but with an alternative
DGP}\label{repeat-parts-5-7-but-with-an-alternative-dgp}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Define new DGP function (using a constant average probability instead of }
\CommentTok{#individual predictions)}
\NormalTok{DGP_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, T, a_}\DecValTok{0}\NormalTok{, a_}\DecValTok{1}\NormalTok{, F, L, sig2_e, pi) \{}
  
\NormalTok{  pibar <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(pi)}
  
\NormalTok{  A <-}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DecValTok{1}\NormalTok{, pibar)}
\NormalTok{  epsilon <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(T}\OperatorTok{*}\NormalTok{n, }\DataTypeTok{mean=}\DecValTok{0}\NormalTok{, }\DataTypeTok{sd =} \KeywordTok{sqrt}\NormalTok{(sig2_e)), n, T)}
  
\NormalTok{  Y <-}\StringTok{ }\NormalTok{a_}\DecValTok{0}\OperatorTok{*}\NormalTok{F }\OperatorTok{+}\StringTok{ }\NormalTok{a_}\DecValTok{1}\OperatorTok{*}\NormalTok{L }\OperatorTok{+}\StringTok{ }\NormalTok{epsilon }
\NormalTok{  W <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow=}\NormalTok{n, }\DataTypeTok{ncol=}\NormalTok{T_}\DecValTok{0}\NormalTok{), }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{nrow=}\NormalTok{n, }\DataTypeTok{ncol=}\NormalTok{T}\OperatorTok{-}\NormalTok{T_}\DecValTok{0}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\NormalTok{A}
  
\NormalTok{  data_returned <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\StringTok{"Y"}\NormalTok{ =}\StringTok{ }\NormalTok{Y, }\StringTok{"W"}\NormalTok{ =}\StringTok{ }\NormalTok{W)}
  \KeywordTok{return}\NormalTok{(data_returned)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Run the DGP simulation and estimation process again}
\NormalTok{tau_hat4 <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{nrow =}\NormalTok{ B, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(tau_hat4) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"tau_DID"}\NormalTok{, }\StringTok{"tau_SC"}\NormalTok{, }\StringTok{"tau_SDID"}\NormalTok{)}

\ControlFlowTok{for}\NormalTok{ (b }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{B)\{}
\NormalTok{  draw <-}\StringTok{ }\KeywordTok{DGP_2}\NormalTok{(n, T, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, F, L, sig2_e, pi)}
\NormalTok{  rowsort <-}\StringTok{ }\KeywordTok{order}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T])}
  
\NormalTok{  data_Y <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{Y[rowsort,]}
\NormalTok{  data_W <-}\StringTok{ }\NormalTok{draw}\OperatorTok{$}\NormalTok{W[rowsort,]}
  
\NormalTok{  n_}\DecValTok{0}\NormalTok{ <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(draw}\OperatorTok{$}\NormalTok{W[,T]}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
  
\NormalTok{  tau_hat4[b,}\DecValTok{1}\NormalTok{] <-}\StringTok{      }\KeywordTok{did_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat4[b,}\DecValTok{2}\NormalTok{] <-}\StringTok{       }\KeywordTok{sc_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{  tau_hat4[b,}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\KeywordTok{synthdid_estimate}\NormalTok{(data_Y, }\DataTypeTok{N0 =}\NormalTok{ n_}\DecValTok{0}\NormalTok{, }\DataTypeTok{T0 =}\NormalTok{ T_}\DecValTok{0}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Create the plots for DGP 2}
\NormalTok{tau_hat4 <-}\StringTok{ }\KeywordTok{data.table}\NormalTok{(tau_hat4)}
\NormalTok{p4 <-}\StringTok{ }\KeywordTok{plotting_func}\NormalTok{(}\DataTypeTok{data=}\NormalTok{tau_hat4,}\DataTypeTok{x_string =}\NormalTok{ tau_hat4}\OperatorTok{$}\NormalTok{tau_DID) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Diff-in-Diff"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\OperatorTok{-}\NormalTok{.}\DecValTok{15}\NormalTok{,.}\DecValTok{15}\NormalTok{)}
\NormalTok{p5 <-}\StringTok{ }\KeywordTok{plotting_func}\NormalTok{(}\DataTypeTok{data=}\NormalTok{tau_hat4,}\DataTypeTok{x_string =}\NormalTok{ tau_hat4}\OperatorTok{$}\NormalTok{tau_SC) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Synthetic Controls"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\OperatorTok{-}\NormalTok{.}\DecValTok{15}\NormalTok{,.}\DecValTok{15}\NormalTok{)}
\NormalTok{p6 <-}\StringTok{ }\KeywordTok{plotting_func}\NormalTok{(}\DataTypeTok{data=}\NormalTok{tau_hat4,}\DataTypeTok{x_string =}\NormalTok{ tau_hat4}\OperatorTok{$}\NormalTok{tau_SDID) }\OperatorTok{+}\StringTok{ }
\StringTok{        }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Synthetic Diff-in-Diff"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\OperatorTok{-}\NormalTok{.}\DecValTok{15}\NormalTok{,.}\DecValTok{15}\NormalTok{)}

\NormalTok{p_dgp2 <-}\StringTok{ }\NormalTok{p4 }\OperatorTok{+}\StringTok{ }\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{plot_annotation}\NormalTok{(}
  \DataTypeTok{title =} \StringTok{"DGP 2: Distribution of Estimator Bias"}\NormalTok{,}
  \DataTypeTok{subtitle=} \StringTok{"alpha_0 = alpha_1 = 1"}
\NormalTok{)}

\NormalTok{p_dgp2}
\end{Highlighting}
\end{Shaded}

\includegraphics{PS8-Q2.1_files/figure-latex/plots2-1.pdf}

Under the new DGP, the propensity for treatment is identical across all
observations. That is, assignment to treatment is actually random. Here,
the bias issue for the diff-in-diff estimator largely vanishes. However,
the synthetic diff-in-diff estimator remains more efficient, just as it
was for the original DGP with heterogeneity in treatment propensity.

\end{document}
