---
title: "In-class session 9"
author: "Ishwara Hegde"
date: "05/01/2021"
output: pdf_document
---
        
The goal of this in-class session was :
        
1. Understand the implementation of cross-fitting and see how it differs from
cross validation.

2. Implement a doubly robust estimator for tau (TE parameter) and compare it 
to a simple difference in means that is obtained by cross fitting!

## Preamble 


```{r setup, include=FALSE}
### PREAMBLE 

knitr::opts_chunk$set( warning = FALSE,message = FALSE,echo = TRUE)

```

Loading packages and setting seed :

```{r packload}

#Setting the seed and clearing workspace 
set.seed(1234)
rm(list = ls())

```





## Problem 1

Task: do three simulations (each B times). In the first one fix outcomes and 
treat W as random. In the second one -- do the opposite. 
In the final one -- treat both as random. 

In each simulation compute the difference in means, and compute its variance 
(over simulations)

```{r pob1}

#Setting some parameters

n <- 20


sigma_0 <- 1
sigma_1 <- 2
rho <- 0
tau <- 5
n_1 <- floor(n/2)
n_0 <- n-n_1

B <- 10000

#In this case we are keeping both Y and W as random since we are 
# resimulating them each time 

result_sim_1 <- do.call(c,lapply(1:B,function(b){

	Y_0 <- rnorm(n,sd = sigma_0)
	Y_1 <- tau + Y_0*rho + sqrt(1-rho^2)*rnorm(n,sd = sigma_1)

	
	W <- rep(0,n)
	W[sample(1:n,n_1)] <- 1

	tau_simple <- sum(W*Y_1/sum(W) -(1-W)*Y_0/sum(1-W))
	
}))

var_sim_1 <- sum((result_sim_1-tau)^2)/B


# Now I keep W fixed but Y random 

W <- rep(0,n)
W[sample(1:n,n_1)] <- 1

result_sim_2 <- do.call(c,lapply(1:B,function(b){

	Y_0 <- rnorm(n,sd = sigma_0)
	Y_1 <- tau + Y_0*rho + sqrt(1-rho^2)*rnorm(n,sd = sigma_1)

	tau_simple <- sum(W*Y_1/sum(W) -(1-W)*Y_0/sum(1-W))
	
}))

var_sim_2 <- sum((result_sim_2-tau)^2)/B


# Now keeping Y fixed and W is random 

Y_0 <- rnorm(n,sd = sigma_0)
Y_1 <- tau + Y_0*rho + sqrt(1-rho^2)*rnorm(n,sd = sigma_1)

result_sim_3 <- do.call(c,lapply(1:B,function(b){


	W <- rep(0,n)
	W[sample(1:n,n_1)] <- 1

	tau_simple <- sum(W*Y_1/sum(W) -(1-W)*Y_0/sum(1-W))
	
}))


var_sim_3 <- sum((result_sim_3-tau)^2)/B
var_st <- sigma_0^2/n_0 + (sigma_0^2*rho^2 + sigma_1^2*(1-rho^2))/n_1

results_var <- round(c(var_sim_1,var_sim_2,var_sim_3,var_st),2)



results_var

``` 

Notice how the variance is different in each case. We know by cosntruction 
that the variance is 0.50. Therefore, what we decide to treat as random 
clearly has some implications. 



## Problem 2

Task: implement two different randomization schemes: half of cities or half of 
units in each city. 

Simulate B times and compute the difference in means. Compute the variance over
B simulations.


We need to cluster at the level of randomization:

```{r prob2}
#Clearing workspace and setting seed 

rm(list = ls())
set.seed(1234)


n <- 50
k <- 10



sigma_mu <- 1
sigma_eps <- 2
tau <- 5
mu_k <- rnorm(k,sd = sigma_mu)


B <- 10000

sim_results <- do.call(rbind,lapply(1:B,function(b){

	eps <- rnorm(n*k,sd = sigma_eps)
	
	Y_0 <- eps + rep(mu_k,each = n)
	Y_1 <- Y_0 + tau

	W_1_k <- rep(0,k)
	W_1_k[sample(1:k,k/2)] <- 1
	W_1 <- rep(W_1_k,each = n)

	W_2 <- rep(0,n*k)
	index_rand <- outer(sample(1:n,n/2),1:k, function(x,y){x+n*(y-1)})
	W_2[index_rand] <- 1
	

	est_1 <- sum(Y_1*W_1/sum(W_1) -Y_0*(1-W_1)/sum(1-W_1))
	est_2 <- sum(Y_1*W_2/sum(W_2) -Y_0*(1-W_2)/sum(1-W_2))
	
	return(c((est_1-tau)^2,(est_2-tau)^2))
}))
	
results_var <- round(colMeans(sim_results),2)


```


```{r prob3}
n <- 20


sigma_0 <- 1
sigma_1 <- 1
rho <- 0.5
tau <- 4
n_1 <- floor(n/2)
n_0 <- n-n_1
B <- 4000

Y_0 <- rnorm(n,sd = sigma_0)
Y_1 <- tau + Y_0*rho + sqrt(1-rho^2)*rnorm(n,sd = sigma_1)


W_obs <- rep(0,n)
W_obs[sample(1:n,n_1)] <- 1
Y_obs <- W_obs*Y_1 + (1-W_obs)*Y_0
tau_simple <- sum(W_obs*Y_1/sum(W_obs) -(1-W_obs)*Y_0/sum(1-W_obs))


result_sim <- do.call(c,lapply(1:B,function(b){

	Y_1 <- Y_obs
	Y_0 <- Y_obs
	W <- rep(0,n)
	W[sample(1:n,n_1)] <- 1
	tau_simple <- sum(W*Y_1/sum(W) -(1-W)*Y_0/sum(1-W))

}))

dens_est <- my_density_function(result_sim,100,deg = 3)[,c(1,3)]
q_95 <- quantile(abs(result_sim),probs = 0.95)



plot(dens_est,main = 'Distribution of the estimators', col = 'black',
     lty = 1,type = 'l',xlab = 'Estimates',ylab = 'Density')
abline(v = tau_simple, lty = 2,lwd = 0.5,col = 'black')
abline(v = q_95, lty = 2,lwd = 0.5,col = 'red')
abline(v = -q_95, lty = 2,lwd = 0.5,col = 'red')

```

```{r plotfunc}

rm(list = ls())
set.seed(1234)


my_density_function <- function(x,K,deg){

	x_min <- min(x)
	x_max <- max(x)
	range_x <- x_max - x_min
	low_x <- x_min - 0.2*range_x
	up_x <- x_max + 0.2*range_x
	range_full <-up_x- low_x
	splits <- seq(low_x,up_x,length.out = K+1)
	mesh_size <- splits[2] - splits[1]
	centers <- (splits[-1]+splits[-(K+1)])/2
	counts <- as.vector(table(cut(x,splits,include.lowest = TRUE)))
	scale <- sum(counts)*mesh_size
	
	data_matrix <- splines::ns(centers, df = deg)
	pois_reg_res <- glm(counts~data_matrix, family = 'poisson')
	freq_pois <- exp(pois_reg_res$linear.predictors)
	dens_pois <- freq_pois/scale
	

	return(cbind(centers,freq_pois,dens_pois))
}
	

```





